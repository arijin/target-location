{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/arijin/dataset/KITTI/kitti_tool\")\n",
    "\n",
    "import os\n",
    "DATASET_ROOT_PATH = '/home/arijin/dataset/KITTI'\n",
    "CALIB_PATH = os.path.join(DATASET_ROOT_PATH, 'object', 'training', 'calib')\n",
    "IMG_LEFT_PATH = os.path.join(DATASET_ROOT_PATH, 'object', 'training', 'image_2')\n",
    "IMG_RIGHT_PATH = os.path.join(DATASET_ROOT_PATH, 'object', 'training', 'image_3')\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import kitti_util_copy as kitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断所有的sift计算的匹配点对中，左点必须在其中一个左图的bbox中，右点必须在右图的bbox中，bbox是在detect出来的。\n",
    "# arg：kp1, kp2, goods对应了使用sift.sift函数output的参数；\n",
    "#      detection1, detection2分别是左图和右图detect出来的信息list。\n",
    "# output：new_goods，剩下的满足上述条件的匹配点对。\n",
    "#         cost，左图和右图中对应bbox中存在的匹配点对数量构成的cost矩阵。大小是M*N，M是左图detect出来的bbox数量，M是右图detect出来的bbox数量\n",
    "#         good_in_detection，存储了按照cost矩阵里对应的匹配点的信息\n",
    "def isgoodinbbox(kp1, kp2, goods, detection1, detection2):\n",
    "    new_goods = []\n",
    "    N = len(detection1)\n",
    "    M = len(detection2)\n",
    "    cost = np.zeros(shape=(N, M))   # Cost matrix\n",
    "    good_in_detection = []\n",
    "    for i in range(N):\n",
    "        temp = []\n",
    "        for j in range(M):\n",
    "            temp.append([])\n",
    "        good_in_detection.append(temp)\n",
    "    for good in goods:\n",
    "        left, right = -1, -1\n",
    "        for i, detection in enumerate(detection1):\n",
    "            xmin, ymin, xmax, ymax = detection[2][0], detection[2][1], detection[2][2], detection[2][3]\n",
    "            if kp1[good[0].queryIdx].pt[0]>xmin and \\\n",
    "               kp1[good[0].queryIdx].pt[0]<xmax and \\\n",
    "               kp1[good[0].queryIdx].pt[1]>ymin and \\\n",
    "               kp1[good[0].queryIdx].pt[1]<ymax:\n",
    "                left = i\n",
    "                break\n",
    "        for j, detection in enumerate(detection2):\n",
    "            xmin, ymin, xmax, ymax = detection[2][0], detection[2][1], detection[2][2], detection[2][3]\n",
    "            if kp2[good[0].trainIdx].pt[0]>xmin and \\\n",
    "               kp2[good[0].trainIdx].pt[0]<xmax and \\\n",
    "               kp2[good[0].trainIdx].pt[1]>ymin and \\\n",
    "               kp2[good[0].trainIdx].pt[1]<ymax:\n",
    "                right = j\n",
    "                break\n",
    "        if left>=0 and right>=0:\n",
    "            new_goods.append(good)\n",
    "            good_in_detection[left][right].append(good[0])\n",
    "            cost[left][right] += 1\n",
    "    return new_goods, cost, good_in_detection\n",
    "\n",
    "# 双目两幅图中匹配的点，通过三角测量的方法恢复此点在真实空间的三维坐标。\n",
    "# kp1，kp2是cv::keypoint类型的点，一个是左图的点，一个是右图的点；\n",
    "# P1, P2分别是由三维空间点到左图和右图的变换矩阵，3*4大小\n",
    "def Triangulate(kp1, kp2, P1, P2):\n",
    "    P1_row0 = np.array(calib.P[0])\n",
    "    P1_row1 = np.array(calib.P[1])\n",
    "    P1_row2 = np.array(calib.P[2])\n",
    "    P2_row0 = np.array(calib.P2[0])\n",
    "    P2_row1 = np.array(calib.P2[1])\n",
    "    P2_row2 = np.array(calib.P2[2])\n",
    "    A_row0 = kp1.pt[0] * P1_row2 - P1_row0\n",
    "    A_row1 = kp1.pt[1] * P1_row2 - P1_row1\n",
    "    A_row2 = kp2.pt[0] * P2_row2 - P2_row0\n",
    "    A_row3 = kp2.pt[1] * P2_row2 - P2_row1\n",
    "    A = np.vstack([A_row0, A_row1, A_row2, A_row3])\n",
    "    U, S, Vh = np.linalg.svd(A)\n",
    "    P = Vh[-1,:]\n",
    "    P = P/P[3]\n",
    "    return P[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "finish.\n",
      "0.5999557971954346\n",
      "[[79.  3.  0.  0.  3.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0. 21.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 17.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 50.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 19.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.  0.]]\n",
      "4500 4147 1054 238\n",
      "[-1.33922072  0.7777092   7.50109797]\n",
      "[ 1.22150064  0.86190286 13.81768853]\n",
      "[ 1.0743857   0.18483196 -1.19765894]\n",
      "[ 7.28444849  0.91495633 33.93589222]\n",
      "[3.97484733 1.06493194 5.58433077]\n",
      "[ 8.09458954  1.10579471 19.50097075]\n",
      "[23.7874704   0.29805053 83.78048633]\n",
      "[10.70812233  1.28158053 41.71651452]\n",
      "[24.69148952  0.72290541 70.37359817]\n",
      "[ 34.78831572  -0.32630121 110.2948883 ]\n",
      "0.8379285335540771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import darknet.darknet as darknet\n",
    "import detect\n",
    "import sift\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 把图片文件读进来\n",
    "frame = 8\n",
    "img_left_file = '{:0>6d}.png'.format(frame)\n",
    "img1 = cv2.imread(os.path.join(IMG_LEFT_PATH, img_left_file))  # queryImage\n",
    "img_right_file = '{:0>6d}.png'.format(frame)\n",
    "img2 = cv2.imread(os.path.join(IMG_RIGHT_PATH, img_right_file))  # trainImage\n",
    "\n",
    "# yolo模型参数初始化\n",
    "print('loading...')\n",
    "netMain, metaMain = detect.yolo_initialize()\n",
    "print('finish.')\n",
    "\n",
    "prev_time = time.time()\n",
    "# 使用opencv中的sift进行关键点提取和匹配，封装好了函数在sift.py中\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "# 调用sift.py中的函数获取匹配点信息\n",
    "kp1, kp2, goods = sift.sift(gray1, gray2)\n",
    "pts1, pts2 = cv2.KeyPoint_convert(kp1), cv2.KeyPoint_convert(kp2)\n",
    "print(time.time()-prev_time)\n",
    "\n",
    "# detect：yolo的图片变量初始化\n",
    "# Create an image we reuse for each detect\n",
    "darknet_image = darknet.make_image(darknet.network_width(netMain),\n",
    "                                   darknet.network_height(netMain),3)\n",
    "# detect1：左图的detect的bbox种类，坐标的获取，经我们的坐标变换，detections1的bbox信息对应的是原图。\n",
    "frame_read = img1.copy()\n",
    "frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)\n",
    "frame_resized = cv2.resize(frame_rgb,\n",
    "                           (darknet.network_width(netMain),\n",
    "                            darknet.network_height(netMain)),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())\n",
    "\n",
    "detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.45)\n",
    "shape1 = frame_read.shape\n",
    "shape2 = (darknet.network_width(netMain), darknet.network_height(netMain), 3)\n",
    "detections1 = detect.convertBack(detections, shape2, shape1)\n",
    "\n",
    "# detect2：右图的detect的bbox种类，坐标的获取\n",
    "frame_read = img2.copy()\n",
    "frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)\n",
    "frame_resized = cv2.resize(frame_rgb,\n",
    "                           (darknet.network_width(netMain),\n",
    "                            darknet.network_height(netMain)),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())\n",
    "\n",
    "detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.45)\n",
    "shape1 = frame_read.shape\n",
    "shape2 = (darknet.network_width(netMain), darknet.network_height(netMain), 3)\n",
    "detections2 = detect.convertBack(detections, shape2, shape1)\n",
    "\n",
    "# filter：进行第一次的匹配点的筛选\n",
    "new_goods, cost, match_in_detection = isgoodinbbox(kp1, kp2, goods, detections1, detections2)\n",
    "print(cost)\n",
    "print(len(kp1), len(kp2), len(goods), len(new_goods))\n",
    "\n",
    "# distance measurement：\n",
    "# 先进行左图和右图的同一个物体的bbox匹配；\n",
    "# 再将bbox对中的匹配的关键点对使用三角测量的方法计算对应空间点的坐标；\n",
    "# 最后取平均\n",
    "calib_file = '{:0>6d}.txt'.format(frame)\n",
    "calib = kitti.Calibration(os.path.join(CALIB_PATH, calib_file))\n",
    "Pos_for_detections = []\n",
    "for i in range(cost.shape[0]):\n",
    "    j = np.argmax(cost[i])  # 对于左图的某一个bbox，在右图中选取最有可能与其是同一个物体的bbox。\n",
    "    goods_in_detection = match_in_detection[i][j]\n",
    "    pts_Pos = []\n",
    "    for good_in_detection in goods_in_detection:\n",
    "        pt_Pos = Triangulate(kp1[good_in_detection.queryIdx], kp2[good_in_detection.trainIdx], calib.P, calib.P2)\n",
    "        pts_Pos.append(pt_Pos)\n",
    "    pts_Pos = np.array(pts_Pos)\n",
    "    Pos = np.mean(pts_Pos, axis=0)\n",
    "    print(Pos)\n",
    "    Pos_for_detections.append(Pos)\n",
    "    \n",
    "print(time.time()-prev_time)\n",
    "\n",
    "# visualize\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "image = detect.cvDrawBoxes_on_origin_img(detections1, Pos_for_detections, img1)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('Demo1', image)\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "# img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,new_goods[:], None, flags=2)\n",
    "# plt.imshow(img3),plt.show()\n",
    "# cv2.imshow(\"MatchDemo\", img3)\n",
    "# cv2.waitKey(10000)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
